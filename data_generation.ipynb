{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "data_generation.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MiHess/cxr-bse/blob/master/data_generation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "vBj2A94g4bKM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "import glob\n",
        "import numpy as np\n",
        "import PIL\n",
        "import logging\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "plt.style.use('default')\n",
        "\n",
        "from collections import defaultdict\n",
        "from tqdm import tqdm\n",
        "\n",
        "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6x8b_S7dxw4u",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "logger = logging.getLogger()\n",
        "logger.setLevel(logging.INFO)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "aAkx3FsZRGKG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "150ff0eb-953f-4ad2-9f3d-5433f74ede3b"
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive/', force_remount=True)\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "MW8KsUFa4TYs",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "bse_data_path = \"/content/drive/My Drive/dev/bse/data\"\n",
        "\n",
        "jsrt_bse_path = os.path.join(bse_data_path, \"jsrt_bse\")\n",
        "\n",
        "jsrt_path = os.path.join(bse_data_path, \"jsrt\")\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "CqdJseqN6l_-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def _load_grayscale_image(filepath):\n",
        "    \"\"\"\n",
        "    \"\"\"\n",
        "    img_array = np.array(load_img(filepath))[:,:,1]\n",
        "    \n",
        "    return img_array.reshape((1,) + img_array.shape)  \n",
        "    \n",
        "\n",
        "def get_train_test_data(X_images_path, y_images_path, test_fraction=0.2):\n",
        "    \"\"\" Loads all images from disk to memory and returns them as numpy array.\n",
        "    \"\"\"\n",
        "    EXPECTED_TOTAL_NUMBER = 247\n",
        "    \n",
        "    X_image_filepaths = sorted(glob.glob(os.path.join(X_images_path, \"*.png\")))\n",
        "    y_image_filepaths = sorted(glob.glob(os.path.join(y_images_path, \"*.png\")))\n",
        "    \n",
        "    if (len(X_image_filepaths) != EXPECTED_TOTAL_NUMBER) or (len(y_image_filepaths) != EXPECTED_TOTAL_NUMBER):\n",
        "        raise ValueError(f\"expected {EXPECTED_TOTAL_NUMBER} images. \"\n",
        "            f\"Found {len(X_image_filepaths)} X and {len(y_image_filepaths)} y images, respectively.\")\n",
        "    else:\n",
        "        logger.info(f\"Found {len(X_image_filepaths)} X images and {len(y_image_filepaths)} y images.\")    \n",
        "\n",
        "    X_images = []\n",
        "    y_images = []\n",
        "    for X_image_filepath, y_image_filepath in zip(X_image_filepaths, y_image_filepaths):\n",
        "        if os.path.basename(X_image_filepath) == os.path.basename(y_image_filepath):\n",
        "            X_images.append(_load_grayscale_image(X_image_filepath))\n",
        "            y_images.append(_load_grayscale_image(y_image_filepath))\n",
        "        else:\n",
        "            raise ValueError(f\"image names do not match: {X_image_filepath} and {y_image_filepath}\")\n",
        "        \n",
        "    test_idc = random.sample(range(EXPECTED_TOTAL_NUMBER), int(EXPECTED_TOTAL_NUMBER * test_fraction))\n",
        "    train_idc = [idx for idx in range(EXPECTED_TOTAL_NUMBER) if idx not in test_idc]\n",
        "    \n",
        "    return np.array(X_images)[train_idc], np.array(y_images)[train_idc], \\\n",
        "        np.array(X_images)[test_idc], np.array(y_images)[test_idc]\n",
        "        \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YW7gY4l1y6q8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1cc57e5e-723a-4ec4-86d9-88f5e6f54e5e"
      },
      "cell_type": "code",
      "source": [
        "X_train, y_train, X_test, y_test = get_train_test_data(jsrt_path, jsrt_bse_path)"
      ],
      "execution_count": 128,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:root:Found 247 X images and 247 y images.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "94Kyex-6_a4x",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9ba922d4-9583-430c-9518-a3b565dd7ecf"
      },
      "cell_type": "code",
      "source": [
        "X_train.shape\n",
        "y_train.shape\n",
        "X_test.shape\n",
        "y_test.shape"
      ],
      "execution_count": 132,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(49, 1, 512, 512)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 132
        }
      ]
    },
    {
      "metadata": {
        "id": "JXa8j8TAuHtn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d30a4798-8b80-4256-f712-20c4ecfc4973"
      },
      "cell_type": "code",
      "source": [
        "batch_size = 16\n",
        "\n",
        "# this is the augmentation configuration we will use for training\n",
        "train_datagen = ImageDataGenerator(\n",
        "        rescale=1./255,\n",
        "        shear_range=0.2,\n",
        "        zoom_range=0.2,\n",
        "        horizontal_flip=True)\n",
        "\n",
        "# this is the augmentation configuration we will use for testing:\n",
        "# only rescaling\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "# this is a generator that will read pictures found in\n",
        "# subfolers of 'data/train', and indefinitely generate\n",
        "# batches of augmented image data\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "        jsrt_bse_path,  # this is the target directory\n",
        "        target_size=(150, 150),  # all images will be resized to 150x150\n",
        "        batch_size=batch_size,\n",
        "        color_mode=\"grayscale\",\n",
        "        class_mode=\"input\")  # since we use binary_crossentropy loss, we need binary labels"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 0 images belonging to 0 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "RFzkwy6mtQRE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_datagen = ImageDataGenerator(\n",
        "        rescale=1./255,\n",
        "        shear_range=0.2,\n",
        "        zoom_range=0.2,\n",
        "        horizontal_flip=True)\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "        'data/train',\n",
        "        target_size=(150, 150),\n",
        "        batch_size=32,\n",
        "        class_mode='binary')\n",
        "\n",
        "validation_generator = test_datagen.flow_from_directory(\n",
        "        'data/validation',\n",
        "        target_size=(150, 150),\n",
        "        batch_size=32,\n",
        "        class_mode='binary')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7uyEdboBs8nz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "y_train = np_utils.to_categorical(y_train, num_classes)\n",
        "y_test = np_utils.to_categorical(y_test, num_classes)\n",
        "\n",
        "datagen = ImageDataGenerator(\n",
        "    featurewise_center=True,\n",
        "    featurewise_std_normalization=True,\n",
        "    rotation_range=20,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    horizontal_flip=True)\n",
        "\n",
        "# compute quantities required for featurewise normalization\n",
        "# (std, mean, and principal components if ZCA whitening is applied)\n",
        "datagen.fit(x_train)\n",
        "\n",
        "# fits the model on batches with real-time data augmentation:\n",
        "model.fit_generator(datagen.flow(x_train, y_train, batch_size=32),\n",
        "                    steps_per_epoch=len(x_train) / 32, epochs=epochs)\n",
        "\n",
        "# here's a more \"manual\" example\n",
        "for e in range(epochs):\n",
        "    print('Epoch', e)\n",
        "    batches = 0\n",
        "    for x_batch, y_batch in datagen.flow(x_train, y_train, batch_size=32):\n",
        "        model.fit(x_batch, y_batch)\n",
        "        batches += 1\n",
        "        if batches >= len(x_train) / 32:\n",
        "            # we need to break the loop by hand because\n",
        "            # the generator loops indefinitely\n",
        "            break"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "RC41sIjOK4tp",
        "colab_type": "code",
        "outputId": "32a3f52a-8319-488a-fbbd-d0c12eb55321",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "raw_jsrt_filepaths = glob.glob(os.path.join(raw_jsrt_path, \"*.IMG\"))\n",
        "\n",
        "for raw_jsrt_bse_filepath in tqdm(raw_jsrt_bse_filepaths):\n",
        "    process_raw_image(raw_jsrt_bse_filepath, load_raw_jsrt_bse_image, target_jsrt_bse_path)\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 247/247 [03:21<00:00,  1.65it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    }
  ]
}